# Fine-tune
我们也完全可以利用我们自己的数据，创建一个新的模型来回答问题。这个方法，就是 OpenAI 提供的模型微调（Fine-tune）功能。

模型微调，是因为无论是 ChatGPT 还是 GPT-4 都不是全知全能的 AI。在很多垂直的领域，它的回答还是常常会出错。
其中很大一部分原因，是它也缺少特定领域的训练数据。而如果我们有比较丰富的垂直领域的数据，那么就可以利用这些数据来“微调”一个特别擅长这个垂直领域的模型。

在这个模型“微调”完成之后，我们就可以直接向模型提问了。
而不用再像之前使用 llama-index 或者 LangChain 那样，先通过 Embedding 来查询相关资料，然后把查找到的资料也一并提交给 OpenAI 来获得所需要的答案。

OpenAI 模型微调的过程，并不复杂。你只需要把数据提供给 OpenAI 就好了，对应的整个微调的过程是在云端的“黑盒子”里进行的。需要提供的数据格式是一个文本文件，每一行都是一个 Prompt，以及对应这个 Prompt 的 Completion 接口会生成的内容。
```
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
```
模型微调的过程，就是根据输入的内容，在原来的基础模型上训练。每一个示例，都会导致基础模型原有参数发生变化。整个微调过程结束之后，变化后的参数就会被固定下来，变成一个只有你可以使用的新模型。

如果你提供了很多医疗行业的文本内容，那么微调出来的新模型就会拥有更多医疗领域的知识，以及对话的风格。而如果你给的是笑话大全，那么微调出来的模型就更擅长讲笑话。微调之后的模型，不仅有你用来微调的数据的相关知识，原先基础模型里面的绝大部分知识和能力它也还都保留着。

-> story.py

使用微调模型的成本要远远高于使用 OpenAI 内置的模型。

以 Davinci 为基础微调的模型，使用的时候，每 1000 个 Token 的成本是 0.12 美元，是使用内置的 text-davinci-003 的 6 倍，
是我们最常用的 gpt-3.5-turbo 的 60 倍。

所以，如果只是一般的讲故事的应用，这个成本实在是太高了。就算是我们选择基于 Curie 微调，1000 个 Token 的使用成本也在 0.012 美元。