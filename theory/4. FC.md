# FC
在深度学习领域，全连接（Fully Connected，简称FC）通常指的是神经网络中的全连接层（Fully Connected Layer），也称为密集连接层（Dense Layer）。这是一种特殊的网络层，其中，该层的每个神经元都与前一层的所有神经元相连，形成一个完全连接的结构。这种连接方式区别于卷积层或某些稀疏连接的层，在那些层中，神经元仅与输入数据的一部分相连。

<img src="./images/FC.avif" />

## 全连接层的工作原理：

1. **输入与权重矩阵相乘**：全连接层接收前一层（可能是另一个全连接层、卷积层、池化层等）的输出作为输入。这些输入数据会经过一个权重矩阵（由该层学习得到）的矩阵乘法操作。每个输入特征与权重矩阵中的一列相对应，通过乘法和累加，生成一个标量值，代表了该层的一个神经元的激活前的输出。

2. **偏置项的加入**：除了权重矩阵外，每个神经元还会加上一个偏置项（bias），以确保神经元能够灵活地表示各种函数，包括那些不经过原点的函数。

3. **激活函数**：得到的加权求和结果会传递给一个非线性激活函数，如ReLU（Rectified Linear Unit）、sigmoid或tanh等，以引入非线性，使得网络能够学习复杂的模式。

### 全连接层的作用：

- **特征整合**：在卷积神经网络（CNN）等结构中，全连接层通常位于最后几层，负责将之前层（如卷积层和池化层）提取的局部特征整合成全局特征，用于最终的分类或回归任务。
- **决策制定**：通过学习到的权重，全连接层能够基于前面层提供的特征，做出最终的分类决策或回归预测。

### 注意事项：

- **参数数量**：全连接层由于其完全连接的特性，通常包含大量的可学习参数，这可能导致过拟合风险，尤其是在数据量有限的情况下。因此，在实践中，全连接层常与其他技术（如正则化、Dropout）配合使用，以减少过拟合。
- **计算成本**：全连接层的计算成本较高，特别是在输入特征维度很大的情况下，这限制了它们在某些资源受限环境下的应用。