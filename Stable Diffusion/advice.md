# advice
arxiv 网站上几乎每天都会更新AICG领域内最新论文。
能明显感觉到，在 AIGC 领域内，几乎每天都有新论文、新方案被提出。
给人的感觉是稍不留神就会掉队，但是真正一头扎进去，又会发现新论文、新技术根本学不完。

面对这个问题，建议是：
不必追求大而全，跟紧自己最感兴趣的那一部分就够了，其余方向定期关注技术资讯就好。
比如，我们的主线是以 SD 模型 AI 绘画技术，对于文生 3D、文生数字人我们只需要关注最里程碑式的工作即可。


多模态生成与多模态理解在未来会有大一统的方案，倾向于是 GPT 统一掉 AI 绘画。这件事情的标志是什么呢？
我觉得应该是出现这样一个模型，它的输入是文字和图片，输出是离散化的 token。
而这些 token 可以重建为文字或者高质量的图像。如果这一天真的到来，属于扩散模型的时代也许就要过去了。


掌握了 AI 绘画的基础知识和经典解决方案，再去看其他非扩散模型的 AI 绘画方案，我们也会发现很多底层知识是相通的，
对于Stable Diffusion的学习不会白学。

<br>

## 思考题
### 思考题1
如果你想绘制一幅精细化的人物肖像，AI 绘画生成的图像在手部和脸部细节存在瑕疵。这种情况下，有哪些方法可以改善这些问题？

答案：针对这个问题，有多种不同的技巧。
- 更换擅长生成手部、脸部细节的 AI 绘画模型，比如开源社区的 ChilloutMix、Counterfeit、Dreamlike 都是不错的选择，当然，不差钱的同学可以使用 Midjourney。
- 使用负面提示词，指定模型不生成 bad hands, low res face 等。
- 使用 ControlNet 等方案对生成的结构做出一定的限制，比如手部的关键点信息、五官信息等。


### 思考题2
假设你使用图生图模式生成了一张卡通风格的猫的图片，你调整了重绘强度和 prompt，尝试了不同的参数组合，但始终无法获得满意的结果。你观察到生成的图像要么失去了猫的特征，要么与原始图像过于相似。请思考可能的原因，并提出解决方案。

答案：这个问题可能出现的原因是 prompt 描述不够准确，或者没选择合适的重绘强度。如果 prompt 没有明确描述所需的卡通风格特征，模型可能无法准确理解你的期望。另外，重绘强度数值太低可能会使生成的图像过于接近原始图像，而太高则会导致图像与原始图像关联度不高。

解决方案是尝试更准确的 prompt 语句，明确描述所需的卡通风格特征，例如使用描述卡通风格细节的关键词。另外，逐步调整重绘强度数值，观察生成结果的变化。尝试不同的取值范围，找到合适的重绘强度，使生成的图像在保留原始图像特征的同时，与期望的卡通风格更加接近。


### 思考题3
在使用 LoRA 模型生成图像时，如何既保持特定 ID 的角色，同时引入多样化的风格？

答案：如果想平衡保持特定 ID 的角色的同时，引入多样化的风格，我们可以通过合理选择和组合 prompt 语句来实现。

首先，为了保持特定 ID 的角色，可以在 prompt 中明确指定特定 ID 的参数，确保生成的图像与该角色一致。例如，在使用 ChilloutMixss3.0 的人物 ID 保持能力时，可以在 prompt 中使用 `<lora:xss3-0:1>` 来指定特定 ID。

为了引入多样化的风格，我们可以通过在 prompt 中使用其他的 LoRA 模型或风格化参数来实现。例如，可以在 prompt 中使用 `<lora:blindbox_v1_mix:1>` 来引入盲盒版本的风格。通过合理选择和组合这些不同的参数，我们可以在保持特定 ID 的角色的同时，赋予生成的图像不同的风格和特征。

总之，平衡保持特定 ID 的角色和引入多样化的风格需要灵活运用不同的 prompt 语句和参数，以达到所需的效果。

### 思考题4
扩散模型生成速度慢是当前的痛点之一。了解了扩散模型的整体思路，你认为扩散模型的推理可以怎样加速呢？

答案：我提供四个方式，它们都可以用于加速。
- UNet 结构：优化用于预测噪声的 UNet 结构。
- 采样器选择：选择更快速的采样器，以减少采样步数。
- 采用类似 Stable Diffusion 的方案，将扩散模型的过程作用于下采样之后的潜变量空间，而不是原始图像空间。
- 优化交叉注意力中的计算方案，使用 Sparse Attention、Flash Attention 这些方案加速计算等。

### 思考题5
如何改进 Transformer 的自注意力机制，提高它的效率，并减少计算资源需求呢？

答案：在改进自注意力机制的过程中，关键是在降低计算资源需求和保持模型性能之间找到平衡。目前已经有一些改进的方法（如局部和稀疏注意力），将自注意力计算变得更高效。

然而，在这方面仍然有较大的改进空间，特别是如何以最小损失对模型性能保持计算效率。比如后面这两个思路。
- 第一个思路是**局部注意力**。可以尝试将全局注意力逐步转换为局部注意力，在局部范围内计算上下文关系。这种方法减少了要考虑的上下文范围，从而降低了计算资源需求。但它可能在捕捉长距离依赖关系方面效果稍逊一筹。
- 第二个就是**低秩近似**。低秩近似方法将自注意力分解为较低维度的表示，以减少计算并降低资源消耗。这种方法通常在保留关键信息的同时减少了计算复杂度，但也可能影响模型性能。

### 思考题6
VAE 和 Transformer 中的编码器、解码器，在结构、原理、功能上有怎样的不同？

答案：结构上，VAE 的编码器和解码器可以使用各种常见的 CNN、RNN 模型结构。Transformer 的编码器和解码器使用的是多头注意力机制 +Feed Forward 神经网络的结构。

原理上，VAE 训练时将损失函数分为两部分：重建损失和 KL 散度。重建损失关注再现输入，而 KL 散度关注潜在空间的分布。VAE 的核心是用潜在变量捕获低维表示，并使用重参数化技巧进行随机梯度下降优化。Transformer 的编码器目标是捕获长距离依赖，解码器在生成序列时使用自回归模型，每一步生成新的输出，同时考虑之前的输出。

功能上，VAE 适用于生成任务，如生成不同类型的数据（例如图像、文本等）。VAE 学习潜在表示，能够生成与输入数据具有相似特征的新数据。而 Transformer 更适用于自然语言处理任务，如文本翻译、情感分析、文本生成等。

实际使用中，可以灵活组合 VAE 和 Transformer，例如在课程中的情感评论生成任务中，使用 Transformer 作为 VAE 的编码器和解码器，进一步改进模型的表现。

<br>

## summary

<img src="./images/summary.webp" />