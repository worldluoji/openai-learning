# Diffusion
DALL-E 2、Imagen、Stable Diffusion 这些大名鼎鼎的模型，它们背后的魔术师都是扩散模型。

扩散模型的灵感源自热力学。我们可以想象一下这样的过程，朝着一杯清水中滴入一滴有色碘伏，然后观察这杯水。
你会发现，碘伏在水中会有一个扩散的过程，最终完全在水中呈现出均匀的状态。扩散效应代表从有序到混乱的过程。

AI 绘画中的扩散模型和上面的例子类似，对于一张图片，逐渐加入噪声，最终图像将变成一张均匀的噪声图:

<img src="./images/add%20noise.webp" />

如果把这个过程反过来，从一个随机噪声图出发，逐步去除噪声，可以生成一张高质量的图片，这便达成了 AI 绘画的目的。

<img src="./images/delete%20noise.webp" />

基于扩散模型实现 AI 绘画的精髓就在于，如何实现这个逐步去除噪声的过程。在每一步的去噪过程中，起作用的是一个需要**训练的神经网络，也就是一个 UNet**。

所以，基于扩散模型实现 AI 绘画包括两个过程——加噪过程和去噪过程。

<br>

## 加噪过程
对于 Diffusion 模型的加噪过程，每一步加噪依赖于时间步 t（t 的取值为 1-1000 中的一个整数，代表加噪声的步数）。
t 越接近 0，当前加噪结果越靠近原始图像；t 越接近 1000，当前加噪结果越靠近纯噪声。

<img src="./images/add noise cal.png" />

当我们通过训练得到神经网络 UNet 后，从原始噪声图出发，时间步取 1000，UNet 便可以预测第一次要去除的噪声值。
然后，采样器便可以根据原始噪声图去除当前噪声值得到一张清晰一点儿的带噪声图像。反复重复这个过程，便完成了 AI 绘画的过程。

<img src="./images/del noise cal.png" />

每一步的加噪结果仅依赖于上一步的加噪结果和一个加噪过程，而这个加噪过程依赖于当前时间步 t，因此整个加噪过程可以看成参数化的马尔科夫链。
马尔可夫链是一种数学模型，用于描述随机事件的序列，其中每个事件的概率仅取决于上一个事件的状态，而与过去的事件无关。

具体加噪去噪过程，可以参考论文：https://readpaper.com/pdf-annotate/note?pdfId=4557071478495911937&noteId=1833652073759793152

你只需要记住一个事情: **对于一张干净的图像，可以通过一次计算得到任意 t 步加噪声的结果**。

<br>

## 去噪过程
去噪的过程包括两层含义。
- 第一，如何根据当前时间步的噪声图预测上一步加入的噪声？
- 第二，如何在当前时间步的噪声图上去除这些噪声？

先看第一层含义，如何根据加噪结果和时间步 t 预测噪声呢？这里深度学习模型就能派上用场了！我们希望得到这样一个模型，输入第 t 步加噪结果和时间步 t，预测从第 t-1 步到第 t 步噪声值。

主流的方法是训练一个 UNet 模型来预测噪声图。因为噪声值和输入图的分辨率是一致的，而 UNet 模型常用于图像分割任务，输入输出的分辨率相同，使用 UNet 来完成这个任务再合适不过了。


接下来是第二层含义。假定我们能够成功预测出这个噪声图，又如何去除噪声呢？答案是采样器，你可能已经从 WebUI 中见到过各种各样的采样器，比如 DDIM、Eular A 等。采样器的作用便是根据加噪结果和噪声值，准确地去除噪声。

<br>

## 训练和推理
训练针对的是刚刚提到的 UNet 黑盒，推理环节指的是从一个高斯噪声出发得到一张干净的图片。

<img src="./images/train and deduce.webp" />

对于训练过程，假定我们已经收集了一个用于训练扩散模型的训练集，整个训练过程便是不断重复下面这六个步骤。
- 每次从数据集中随机抽取一张图片。
- 随机从 1 至 1000 中选择一个时间步 t。
- 随机生成一个高斯噪声。
- 根据上述加噪环节的公式，一次计算直接得到第 t 步加噪的结果图像。
- 将时间步 t 和加噪图像作为 UNet 的输入去预测一个噪声值。
- 使用第五步预测的噪声值和第三步随机生成的噪声值，计算数值误差，并回传梯度

计算数值误差的公式如下图所示，细心的你一定已经发现了，这里用到的正是 L2 损失:

<img src="./images/L2.webp" />

当我们反复循环上面的过程，直到 UNet 的损失函数逐渐收敛到较小的数值时，比如观测一段时间，损失函数的数值不再降低，就代表我们的扩散模型就训练完成了！

训练的代码：
```
for i, (x_0) in enumerate(tqdm_data_loader): 
    # 将数据加载至相应的运行设备(device)
    x_0 = x_0.to(device)  
    
    # 对每一张图片随机在1~T的扩散步中进行采样
    t = torch.randint(1, T, size=(x_0.shape[0],), device=device)
    
    # 取得不同t下的 根号下alpha_t的连乘  
    sqrt_alpha_t_bar = torch.gather(sqrt_alphas_bar, dim=0, index=t).reshape(-1, 1, 1, 1)  
    
    # 取得不同t下的 根号下的一减alpha_t的连乘
    sqrt_one_minus_alpha_t_bar = torch.gather(sqrt_one_minus_alphas_bar, dim=0, index=t).reshape(-1, 1, 1, 1)
    
    # 从标准正态分布中采样得到 \epsilon 
    noise = torch.randn_like(x_0).to(device) 
    
    # 计算x_t 
    x_t = sqrt_alpha_t_bar * x_0 + sqrt_one_minus_alpha_t_bar * noise  
    
    # 将x_t输入模型 unet，得到输出
    out = net_model(x_t, t)  
    
    loss = loss_function(out, noise) # 将模型的输出，同添加的噪声做损失
    optimizer.zero_grad()  # 优化器的梯度清零
    loss.backward()  # 由损失反向求导
    optimizer.step()  # 优化器更新参数
```

训练好了 UNet 模型以后，我们就可以用它来进行推理了，也就是从噪声开始生成图像。一次去噪过程包括三步:
- 我们随机生成一个高斯噪声，作为第 1000 步加噪之后的结果。
- 将这个噪声和时间步 1000 作为已经训练好的 UNet 的输入，预测第 999 步引入的噪声。
- 使用采样器在步骤 1 的高斯噪声中去除步骤 2 预测的噪声，得到一张干净一点的图像。

这样我们就完成了一次去噪，然后以刚得到的干净一点的图像作为起点，重复第二步、第三步，便可以得到进一步去噪的图像。对于 DDPM 这个“黑盒”采样器来说，将上述过程重复 1000 次，我们便完成了从高斯噪声得到清晰图片的过程。

推理的代码如下：
```
for t_step in reversed(range(T)):  # 从T开始向零迭代
    t = t_step
    t = torch.tensor(t).to(device)
    # 如果t大于零，则采样自标准正态分布，否则为零
    z = torch.randn_like(x_t,device=device) if t_step > 0 else 0  
    
    """这里作为示例，按照DDPM采样器公式计算"""
    x_t_minus_one = torch.sqrt(1/alphas[t])*
           (x_t-(1-alphas[t])*model(x_t, t.reshape(1,))/torch.sqrt(1-alphas_bar[t]))
           +torch.sqrt(betas[t])*z
    
    x_t = x_t_minus_one   
```

<br>

## Diffusion vs GAN

<img src="./images/Diffusion%20VS%20GAN.webp" />