# GPT
GPT 的英文全称翻译过来就是“生成式预训练 Transformer（Generative Pre-trained Transformer）

预训练模型，就是虽然我们没有看过你想要解决的问题，比如在情感分析里看到的用户评论和评分。但是，我可以拿很多我能找到的文本，比如网页文章、维基百科里的文章，各种书籍的电子版等等，作为理解文本内容的一个学习资料。

可以这样来理解：用来训练的语料文本越丰富，模型中可以放的参数越多，那模型能够学到的关系也就越多。类似的情况在文本里出现得越多，那么将来模型猜得也就越准。

早在 2013 年，就有一篇叫做 Word2Vec 的经典论文谈到过。它能够通过预训练，根据同一个句子里一个单词前后出现的单词，来得到每个单词的向量。而在 2018 年，Google 关于 BERT 的论文发表之后，整个业界也都会使用 BERT 这样的预训练模型，把一段文本变成向量用来解决自己的自然语言处理任务。在 GPT-3 论文发表之前，大家普遍的结论是，BERT 作为预训练的模型效果也是优于 GPT 的。

除了OpenAI外，Meta和Google也有自己GPT:
- Meta的 Fasttext，它继承了 Word2Vec 的思路，能够把一个个单词表示成向量。
- Google 的 T5，T5 的全称是 Text-to-Text Transfer Trasnformer，是适合做迁移学习的一个模型。所谓迁移学习，也就是它推理出来向量的结果，常常被拿来再进行机器学习，去解决其他自然语言处理问题。通常很多新发表的论文，会把 T5 作为预训练模型进行微调和训练.

## 大语言模型的两种模式
大语言模型的原理，就是利用训练样本里面出现的文本的前后关系，通过前面的文本对接下来出现的文本进行概率预测。如果类似的前后文本出现得越多，那么这个概率在训练过程里会收敛到少数正确答案上，回答就准确。如果这样的文本很少，那么训练过程里就会有一定的随机性，对应的答案就容易似是而非。

在 GPT-3 的模型里，虽然整体的训练语料很多，但是中文语料很少。只有不到 1% 的语料是中文的，所以如果问很多中文相关的知识性或者常识性问题，它的回答往往就不准确。

1. 一个解决办法，就是<strong>多找一些高质量的中文语料训练一个新的模型</strong>。或者，对于我们想让 AI 能够回答出来的问题，找一些数据。然后利用 OpenAI 提供的“微调”（Fine-tune）接口，在原来的基础上训练一个新模型出来。
如果是时效性要求比较强的资讯类的信息，就很难这么做。比如，我们想让 AI 告诉我们前一天足球赛的比分，我们不太可能每隔几个小时就单独训练或者微调一下模型，那样干的成本太高了。

2. Bing 的解法——先搜索，后提示.
先通过搜索的方式，找到和询问的问题最相关的语料。这个搜索过程中，我们既可以用传统的基于关键词搜索的技术，也可以用 Embedding 的相似度进行语义搜索的技术。然后，将和问题语义最接近的前几条内容，作为提示语的一部分给到 AI。然后请 AI 参考这些内容，再来回答这个问题。（我们不必从 0 开始写代码。因为这个模式实在太过常用了，所以有人为它写了一个开源 Python 包，叫做 llama-index,
demo: 8. llama-index）

这也揭示了大语言模型其实内含了两种能力：
- 第一种，是海量的语料中，本身已经包含了的知识信息。比如，我们前面问 AI 鱼香肉丝的做法，它能回答上来就是因为语料里已经有了充足的相关知识。我们一般称之为“世界知识”。
- 第二种，是根据你输入的内容，理解和推理的能力。这个能力，不需要训练语料里有一样的内容。而是大语言模型本身有“思维能力”，能够进行阅读理解。这个过程里，“知识”不是模型本身提供的，而是我们找出来，临时提供给模型的。如果不提供这个上下文，再问一次模型相同的问题，它还是答不上来的。

总结一下，通过llama-index ，将外部的资料库索引起来进行问答; 通过 Langchain（9.LLMChain）的链式调用，实时获取外部的数据信息，或者运行 Python 程序, 以及记住对话中我们关心的部分。将这些能力组合起来，我们就可以搭建一个完整的，属于自己的聊天机器人。