# GPT
GPT 的英文全称翻译过来就是“生成式预训练 Transformer（Generative Pre-trained Transformer）

预训练模型，就是虽然我们没有看过你想要解决的问题，比如在情感分析里看到的用户评论和评分。但是，我可以拿很多我能找到的文本，比如网页文章、维基百科里的文章，各种书籍的电子版等等，作为理解文本内容的一个学习资料。

可以这样来理解：用来训练的语料文本越丰富，模型中可以放的参数越多，那模型能够学到的关系也就越多。类似的情况在文本里出现得越多，那么将来模型猜得也就越准。

早在 2013 年，就有一篇叫做 Word2Vec 的经典论文谈到过。它能够通过预训练，根据同一个句子里一个单词前后出现的单词，来得到每个单词的向量。而在 2018 年，Google 关于 BERT 的论文发表之后，整个业界也都会使用 BERT 这样的预训练模型，把一段文本变成向量用来解决自己的自然语言处理任务。在 GPT-3 论文发表之前，大家普遍的结论是，BERT 作为预训练的模型效果也是优于 GPT 的。

除了OpenAI外，Meta和Google也有自己GPT:
- Meta的 Fasttext，它继承了 Word2Vec 的思路，能够把一个个单词表示成向量。
- Google 的 T5，T5 的全称是 Text-to-Text Transfer Trasnformer，是适合做迁移学习的一个模型。所谓迁移学习，也就是它推理出来向量的结果，常常被拿来再进行机器学习，去解决其他自然语言处理问题。通常很多新发表的论文，会把 T5 作为预训练模型进行微调和训练.

<br>

## 大语言模型的两种模式
大语言模型的原理，就是利用训练样本里面出现的文本的前后关系，通过前面的文本对接下来出现的文本进行概率预测。如果类似的前后文本出现得越多，那么这个概率在训练过程里会收敛到少数正确答案上，回答就准确。如果这样的文本很少，那么训练过程里就会有一定的随机性，对应的答案就容易似是而非。

在 GPT-3 的模型里，虽然整体的训练语料很多，但是中文语料很少。只有不到 1% 的语料是中文的，所以如果问很多中文相关的知识性或者常识性问题，它的回答往往就不准确。

1. 一个解决办法，就是<strong>多找一些高质量的中文语料训练一个新的模型</strong>。或者，对于我们想让 AI 能够回答出来的问题，找一些数据。然后利用 OpenAI 提供的“微调”（Fine-tune）接口，在原来的基础上训练一个新模型出来。
如果是时效性要求比较强的资讯类的信息，就很难这么做。比如，我们想让 AI 告诉我们前一天足球赛的比分，我们不太可能每隔几个小时就单独训练或者微调一下模型，那样干的成本太高了。

2. Bing 的解法——先搜索，后提示.
先通过搜索的方式，找到和询问的问题最相关的语料。这个搜索过程中，我们既可以用传统的基于关键词搜索的技术，也可以用 Embedding 的相似度进行语义搜索的技术。然后，将和问题语义最接近的前几条内容，作为提示语的一部分给到 AI。然后请 AI 参考这些内容，再来回答这个问题。（我们不必从 0 开始写代码。因为这个模式实在太过常用了，所以有人为它写了一个开源 Python 包，叫做 llama-index,
demo: 8. llama-index）

这也揭示了大语言模型其实内含了两种能力：
- 第一种，是海量的语料中，本身已经包含了的知识信息。比如，我们前面问 AI 鱼香肉丝的做法，它能回答上来就是因为语料里已经有了充足的相关知识。我们一般称之为“世界知识”。
- 第二种，是根据你输入的内容，理解和推理的能力。这个能力，不需要训练语料里有一样的内容。而是大语言模型本身有“思维能力”，能够进行阅读理解。这个过程里，“知识”不是模型本身提供的，而是我们找出来，临时提供给模型的。如果不提供这个上下文，再问一次模型相同的问题，它还是答不上来的。

总结一下，通过llama-index ，将外部的资料库索引起来进行问答; 通过 Langchain（9.LLMChain）的链式调用，实时获取外部的数据信息，或者运行 Python 程序, 以及记住对话中我们关心的部分。将这些能力组合起来，我们就可以搭建一个完整的，属于自己的聊天机器人。

<br>

## Fine-tune
我们也完全可以利用我们自己的数据，创建一个新的模型来回答问题。这个方法，就是 OpenAI 提供的模型微调（Fine-tune）功能。

模型微调，是因为无论是 ChatGPT 还是 GPT-4 都不是全知全能的 AI。在很多垂直的领域，它的回答还是常常会出错。其中很大一部分原因，是它也缺少特定领域的训练数据。而如果我们有比较丰富的垂直领域的数据，那么就可以利用这些数据来“微调”一个特别擅长这个垂直领域的模型。

在这个模型“微调”完成之后，我们就可以直接向模型提问了。而不用再像之前使用 llama-index 或者 LangChain 那样，先通过 Embedding 来查询相关资料，然后把查找到的资料也一并提交给 OpenAI 来获得所需要的答案。

OpenAI 模型微调的过程，并不复杂。你只需要把数据提供给 OpenAI 就好了，对应的整个微调的过程是在云端的“黑盒子”里进行的。需要提供的数据格式是一个文本文件，每一行都是一个 Prompt，以及对应这个 Prompt 的 Completion 接口会生成的内容。
```
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
```
模型微调的过程，就是根据输入的内容，在原来的基础模型上训练。每一个示例，都会导致基础模型原有参数发生变化。整个微调过程结束之后，变化后的参数就会被固定下来，变成一个只有你可以使用的新模型。

如果你提供了很多医疗行业的文本内容，那么微调出来的新模型就会拥有更多医疗领域的知识，以及对话的风格。而如果你给的是笑话大全，那么微调出来的模型就更擅长讲笑话。微调之后的模型，不仅有你用来微调的数据的相关知识，原先基础模型里面的绝大部分知识和能力它也还都保留着。

demo -> 10. Fine-tune

使用微调模型的成本要远远高于使用 OpenAI 内置的模型。以 Davinci 为基础微调的模型，使用的时候，每 1000 个 Token 的成本是 0.12 美元，是使用内置的 text-davinci-003 的 6 倍，是我们最常用的 gpt-3.5-turbo 的 60 倍。所以，如果只是一般的讲故事的应用，这个成本实在是太高了。就算是我们选择基于 Curie 微调，1000 个 Token 的使用成本也在 0.012 美元。