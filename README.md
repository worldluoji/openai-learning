# OpenAI API learning
OpenAI 就只提供了 Completion 和 Embedding 两个接口，
其中，Completion 可以让模型根据你的输入进行自动续写，Embedding 可以将你输入的文本转化成向量。

## preparation
1. 更新pip
```
python3 -m pip install --upgrade pip
```
2. 安装依赖
```
pip install -r requirements.txt
```

## Completion
Completion 这个接口里面的参数:
1. 第一个参数是 engine，也就是我们使用的是 Open AI 的哪一个引擎，这里我们使用的是 text-davinci-003，也就是现在可以使用到的最擅长根据你的指令输出内容的模型。当然，也是调用成本最高的模型。
2. 第二个参数是 prompt，是我们输入的提示语。
3. 第三个参数是 max_tokens，也就是调用生成的内容允许的最大 token 数量。你可以简单地把 token 理解成一个单词。有时候，一个单词会被分解成两个 token。比如，icecream 是一个单词，但是实际在大语言模型里，会被拆分成 ice 和 cream 两个 token。这里用的 text-davinci-003 模型，允许最多有 4096 个 token。
4. 第四个参数 n，代表你希望 AI 给你生成几条内容供你选择。在这样自动生成客服内容的场景里，我们当然设置成 1。但是如果在一些辅助写作的场景里，你可以设置成 3 或者更多，供用户在多个结果里面自己选择自己想要的。
5. 第五个参数 stop，代表你希望模型输出的内容在遇到什么内容的时候就停下来。这个参数我们常常会选用 "\n\n"这样的连续换行，因为这通常意味着文章已经要另起一个新的段落了，既会消耗大量的 token 数量，又可能没有必要
### example1: "1. hello/hello_openai.py"

上面例子调用了 OpenAI 的 Completion 接口，然后向它提了一个需求，也就是为一个我在 1688 上找到的中文商品名称做三件事情。
- 为这个商品写一个适合在亚马逊上使用的英文标题。
- 给这个商品写 5 个卖点。
- 估计一下，这个商品在美国卖多少钱比较合适。

同时，我们告诉 OpenAI，我们希望返回的结果是 JSON 格式的，并且上面的三个事情用 title、selling_points 和 price_range 三个字段返回。

### example2: "3. prompt/prompt.py"
相同的提示语，连续调用两次之后，给到了含义相同、遣词造句不同的结果。

每次回复的内容不一样，则归功于我们使用的一个参数 temperature。这个参数的输入范围是 0-2 之间的浮点数，代表输出结果的随机性或者说多样性。在这里，我们选择了 1.0，也就是还是让每次生成的内容都有些不一样。你也可以把这个参数设置为 0，这样，每次输出的结果的随机性就会比较小。

这个参数该怎么设置，取决于实际使用的场景。如果对应的场景比较严肃，不希望出现差错，那么设得低一点比较合适，比如银行客服的场景。如果场景没那么严肃，有趣更加重要，比如讲笑话的机器人，那么就可以设置得高一些。

## Embedding
通过大语言模型来进行情感分析，最简单的方式就是利用它提供的 Embedding 这个 API。
这个 API 可以把任何你指定的一段文本，变成一个大语言模型下的向量，也就是用一组固定长度的参数来代表任何一段文本。

example1: -> "2. sentiment analysis/comment_analysis.py"

这个例子中，对于任何一段文本评论，我们都可以通过 API 拿到它的 Embedding。
那么，把这段文本的 Embedding 和“好评”以及“差评”通过余弦距离（Cosine Similarity）计算出它的相似度。
然后拿这个 Embedding 和“好评”之间的相似度，去减去和“差评”之间的相似度，就会得到一个分数。

如果这个分数大于 0，那么说明我们的评论和“好评”的距离更近，我们就可以判断它为好评。
如果这个分数小于 0，那么就是离差评更近，我们就可以判断它为差评。